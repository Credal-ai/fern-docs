---
title: Prompt
---

Here you can provide a background prompt, which will provide the agent with context and instructions on how to handle user queries. By default, Credal instructs agents to be helpful, honest, and to the point and to let users know when it is unsure of the answer.

![agent-prompt.png](/docs/assets/agents/create-steps/agent-prompt.png)

You can revise this prompt to include the background information and instructions relevant to your Agent. When thinking about the level of detail you should provide, consider how you might explain the assignment to a new employee. Your explanation might include:

- Background information on the company;
- Intended users;
- Topics agent will be dealing with;
- Any relevant guidelines or policies;
- Any other relevant considerations.

The content and depth of prompts will vary by use case.

<AccordionGroup>
  <Accordion title="Example Prompt: Federal Rules of Court Agent">
*You are a diligent, objective, detail-oriented, assistant. Your job is to assist lawyers working in a corporate law firm, specializing in litigation. You will answer questions related to the application of rules of civil procedure, including the Federal Rules of Civil Procedure and the local rules applicable to various district courts. You will respond to questions and prompts truthfully.*

_Instructions:_

- _Below is context to help you answer, followed by a prompt: read it and provide a helpful, honest, and to the point answer based only on the context provided._
- _If you're unsure of an answer, you can say "I don't know" or "I'm not sure"._
- _When providing a response, always include a reference to the rule number which contains the answer._

_The Federal Rules of Civil Procedure are procedural rules that apply to civil court cases in United States federal district courts. They govern things like deadlines, pleading requirements, discovery, motion practice, and trials. In addition to the Federal Rules, individual federal district courts can adopt their own Local Rules that provide supplemental procedures. These Local Rules cannot conflict with the Federal Rules, but they can address more specific practices within that district. In a given court district, the Federal Rules and the local rules for that district are applicable, as well as the Chambers Rules of the presiding Judge. Where the rules do not provide an answer to a question, an answer may be located in the Chambers Rules of the presiding judge._

_--- Start Context ---_  
_{{data}}_  
_--- End Context ---_
  </Accordion>

  <Accordion title="Example Prompt: Credal's Information Security Agent">
*You are a friendly helpful, honest assistant, who helps Credal company employees answer questions and prompts truthfully about information security questionnaires. Credal is itself a real AI security company, founded in 2022, in New York City, by two former Palantir Engineers (Ravin Thambapillai and Jack Fischer). Below is contextual information from Credal's documentation to help you answer, followed by a prompt: read it and provide a helpful, honest, and to the point answers based on the context provided. If the answer does not appear in the provided context, say that you do not know. If the answer does appear in the provided context, explain which document you drew the answer from.*

_--------- Context: ---------_  
_{{data}}_  
_--------- End Context ---------_
  </Accordion>
</AccordionGroup>

---

**Suggested Questions** allow you to save prompts that would be frequently used in a given Agent, eliminating the need to repeatedly paste the same prompts.

For instance, in a Agent built to synthesize research reports, you can save the following prompts: Summarize this paper, Extract the results, and List citations.

![agent_suggested_questions.png](/docs/assets/agents/create-steps/agent_suggested_questions.png)

The saved Suggested Questions are displayed below the Agent prompt box and enable the user to auto-populate the prompt in one click.

![agent_saved_suggested_questions.png](/docs/assets/agents/create-steps/agent_saved_suggested_questions.png)

# Writing a Background Prompt

Background prompts are a powerful tool for guiding your agent's behavior. They provide context and instructions to the agent, helping it to understand its role and how to respond to user queries.
The background prompt controls everything from the agent's tone, to the actions it can call, and to the output format it should use. A good background prompt can make the difference between an agent that is helpful and one that is not.

To ensure that you get the most accurate and helpful responses from Credal, it's crucial to craft your prompts effectively.

Here's why prompt engineering is worth your attention:

1. **Improves Accuracy**: Well-crafted prompts lead to more precise and relevant answers, reducing the likelihood of misinterpretations or general responses.
2. **Saves Time**: By clearly directing the AI, you can obtain the desired information with fewer attempts.
3. **Enhances Complexity Handling**: Complex tasks often require nuanced understanding. Good prompts translate intricate questions into a form that the AI can process effectively.
4. **Facilitates Innovation**: Mastering prompt engineering allows you to push the boundaries of AI's applications, driving innovation and enabling new solutions to complex problems.

Here is an overview of all the information that is included in a Credal background prompt and how you can use it to guide your agent:

## Role
Who is the agent? What is their job title? What is their role in the company? Knowing who the agent is will help it understand what it is doing and how to respond to user queries.

## Goal
What is the agent supposed to accomplish? This will help the agent understand what the end result should look like to make sure it is properly helping the user.

## Output Format

How should the agent structure its responses? LLMs can be a bit unpredictable, but luckily we can just tell them what to do with clear instructions. Providing a template for expected responses helps ensure consistency.

Here's an example of setting up an output format for entity extraction:

```
Extract the important entities mentioned in the context.

Output format:
Company names: <comma_separated_list_of_company_names>
People names: <comma_separated_list_of_people_names>
Specific topics: <comma_separated_list_of_specific_topics>
General themes: <comma_separated_list_of_general_themes>
```

Another example:

```
Provide a riddle using the following structure:
- Riddle: <the puzzle or brainteaser>
- Answer: <the solution to the puzzle>
- Difficulty level: <a difficulty rating from 1 (easy) to 10 (challenging)>
```

## Instructions

What steps should the agent take to achieve its ultimate goal? This section controls the overall workflow of the agent. If you want the agent to call actions in a specific order, ask the user for more
information at a specific point, or look at specific data before making a decision, you can specify that all here. 

Craft detailed instructions that anticipate potential pitfalls and standard operational procedures. Your Agent will only know as much as you tell it. Noticing that the responses are too long? Specify response length! Think there's too much fluff in the language? Ask for concise language.

See for an example of what this should look like.
![attaching actions to agents](/docs/assets/actions/attaching-actions.png)

## Provided Prompt Snippets

Credal has prompt snippets right under the background prompt in the Agent Configuration tab. This is a great way to drop phrases into the background prompt that can help improve agents. This can take the form
of telling agents to avoid hallucinations, but can also do things such as improve the total response time of an agent. For example, you can use these snippets to tell the agent to call
tools in parallel or to avoid repeating queries.

![prompt-snippets.png](/docs/assets/prompt-engineering/prompt-snippets.png)

## Complete Example

Here's an example of a fully crafted background prompt:

```
Role and Goal:
You work in Credal's Customer Success team, and your goal is to enhance customer support quality by analyzing interactions for performance improvement and coaching. For each CS interaction transcript, you will provide a score per category and actionable feedback per review tag based on the pinned QA Scorecard.

Output:
1 scoring table with following 2 columns: Category, # of Points
1 feedback table with following 2 columns: Review Tag, Actionable Feedback

Response Guidelines:
-If there are any trust-related issues in the transcript based on the trust-specific review tags in the scorecard, auto-fail the entire ticket and give an overall score of 0; if there are no trust-related issues, put "N/A"
-Scorecard categories have specific corresponding review tags. Give full points in this category only if there are no review tag failures, and 0 points if the transcript contains any of the corresponding review tags
-"# of Points" refers to score per category for the attached transcript
-Include all review tags in the table and each review tag (e.g., "[T] Disclosing private Credal/TaskUs Information e.g. leaking product launches") should be its own row with corresponding feedback
-Make the feedback specific, pull examples from the transcript, and provide sample improved talking points
-Your tone is professional, concise, helpful, and coaching

--- Start Context ---
{{data}}
--- End Context ---
```

## Best Practices

### Start Simple and Iterate

Begin with simple prompts (zero-shot) and evolve to more complex ones (few-shot) as needed:

**Zero-shot Example:**

```
List key features of the following product.
Text: {text}
Features:
```

**Few-shot Example:**

```
Text 1: "The new Credal AI platform offers enhanced data security."
Features 1: enhanced data security
##
Text 2: "Credal AI enables seamless API integration."
Features 2: seamless API integration
##
Text 3: {text}
Features 3:
```

### Be Clear and Specific

Avoid imprecise language. Precise prompts lead to more accurate outcomes:

**Less effective:**
```
The description for this product should be fairly short, a few sentences only.
```

**Better:**
```
Describe this product in a 3 to 5 sentence paragraph.
```

### Say What to Do Instead of What Not to Do

Provide positive instructions to guide the model effectively.

**Less effective:**
```
DO NOT REPEAT.
```

**Better:**
```
Encourage concise problem-solving with clear instructions. Instead of asking the same question, guide the user to review specific troubleshooting steps or the FAQ at www.example.com/FAQ.
```

### Save Your Work with Suggested Questions

If you're a collaborator on an agent, you can copy-paste your crafted prompts into a Suggested Question in the Agent config. Now when you log into the webUI, you can reuse your prompt with the click of a button!

![prompt-engineering.png](/docs/assets/prompt-engineering/prompt-engineering.png)

### Use the Latest Model

Utilize the most recent and capable models to achieve the best results. Newer models are generally more adept at understanding and following your prompts.

### Incorporate Feedback Loops

Continuously refine your prompts based on your impression of Agent responses to improve accuracy and relevance. Negative feedback logs are a great resource for this!

## What Not to Ask

1. Anything about access controls. That's on us, we double check access policies on the Credal side before sending anything to the LLM!
2. Anything about a Credal concept (Agents, Document collections, "pinned" sources, etc.). The LLM doesn't know what these are, we will do the searching and consolidation of information for you.
