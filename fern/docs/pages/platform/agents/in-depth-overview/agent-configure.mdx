Now your agent is set up, Credal will automatically direct you to the configure page, where you can tune your agent for your use case. You can return to this page to edit your settings at any time. Each section of the configuration tab is explained below:

### a. Name and description

The name and description of your agent will already be populated and can be edited here.

### b. AI **Model**


1. **Model Selection**
   - Here you can choose the foundation AI model you want your agent to use from the drop-down menu. More advanced models, like o1, are both more expensive and more capable than earlier models. When selecting a model, you may want to consider your budget, the volume of queries you expect the agent to receive, and the complexity of the task.
   - GPT-4o is a good starting point for most use cases, as it’s very capable and relatively affordable. If you are unsure of the best choice, running some test queries is a good way to gauge a model’s performance for your use case.
   
   ![agent-different-models-dropdown.png](/docs/assets/agents/create-steps/agent-different-models-dropdown.png)

2. **Creativity**
   - You can set the level of creativity you want your agent to have by making a selection from the panel below. For most use cases, you’ll want “precise” or “balanced”. More creativity means the agent will try more unusual responses, while more precision means the agent will rely more on the context and data you provide. 
   - The creativity setting is a bit like having an “eccentric genius” on the team: a lot of what is says may be off, but it’ll occasionally produce something really unique and interesting: most useful for marketing, brainstorming, or creative writing use cases.

   ![agent-model-creativity.png](/docs/assets/agents/create-steps/agent-model-creativity.png)

### c. **Prompt**

Here you can provide a background prompt, which will provide the agent with context and instructions on how to handle user queries. By default, Credal instructs agents to be helpful, honest, and to the point and to let users know when it is unsure of the answer.

![agent-prompt.png](/docs/assets/agents/create-steps/agent-prompt.png)

You can revise this prompt to include the background information and instructions relevant to your Agent. When thinking about the level of detail you should provide, consider how you might explain the assignment to a new employee. Your explanation might include:

- Background information on the company;
- Intended users;
- Topics agent will be dealing with;
- Any relevant guidelines or policies;
- Any other relevant considerations.

The content and depth of prompts will vary by use case.

<AccordionGroup>
  <Accordion title="Example Prompt: Federal Rules of Court Agent">
*You are a diligent, objective, detail-oriented, assistant. Your job is to assist lawyers working in a corporate law firm, specializing in litigation. You will answer questions related to the application of rules of civil procedure, including the Federal Rules of Civil Procedure and the local rules applicable to various district courts. You will respond to questions and prompts truthfully.*

_Instructions:_

- _Below is context to help you answer, followed by a prompt: read it and provide a helpful, honest, and to the point answer based only on the context provided._
- _If you're unsure of an answer, you can say "I don't know" or "I'm not sure"._
- _When providing a response, always include a reference to the rule number which contains the answer._

_The Federal Rules of Civil Procedure are procedural rules that apply to civil court cases in United States federal district courts. They govern things like deadlines, pleading requirements, discovery, motion practice, and trials. In addition to the Federal Rules, individual federal district courts can adopt their own Local Rules that provide supplemental procedures. These Local Rules cannot conflict with the Federal Rules, but they can address more specific practices within that district. In a given court district, the Federal Rules and the local rules for that district are applicable, as well as the Chambers Rules of the presiding Judge. Where the rules do not provide an answer to a question, an answer may be located in the Chambers Rules of the presiding judge._

_--- Start Context ---_  
_{{data}}_  
_--- End Context ---_
  </Accordion>

  <Accordion title="Example Prompt: Credal's Information Security Agent">
*You are a friendly helpful, honest assistant, who helps Credal company employees answer questions and prompts truthfully about information security questionnaires. Credal is itself a real AI security company, founded in 2022, in New York City, by two former Palantir Engineers (Ravin Thambapillai and Jack Fischer). Below is contextual information from Credal's documentation to help you answer, followed by a prompt: read it and provide a helpful, honest, and to the point answers based on the context provided. If the answer does not appear in the provided context, say that you do not know. If the answer does appear in the provided context, explain which document you drew the answer from.*

_--------- Context: ---------_  
_{{data}}_  
_--------- End Context ---------_
  </Accordion>
</AccordionGroup>

**Organization Prompt**: 
This setting, when enabled, appends a fixed set of Credal-provided background instructions to every agent in your organization.
These rules cannot be edited and ensure that all agents follow core ethical and professional guidelines, such as:

   1. Always answering honestly.
   2. Never insulting or maligning any human being, whether they are a Credal employee or otherwise.

This helps maintain consistent, respectful, and trustworthy behavior across all deployed agents.

![agent-organization-prompt.png](/docs/assets/agents/create-steps/agent-organization-prompt.png)

**Suggested Questions** allow you to save prompts that would be frequently used in a given Agent, eliminating the need to repeatedly paste the same prompts.

For instance, in a Agent built to synthesize research reports, you can save the following prompts: Summarize this paper, Extract the results, and List citations.

![agent_suggested_questions.png](/docs/assets/agents/create-steps/agent_suggested_questions.png)

The saved Suggested Questions are displayed below the Agent prompt box and enable the user to auto-populate the prompt in one click.

![agent_saved_suggested_questions.png](/docs/assets/agents/create-steps/agent_saved_suggested_questions.png)


### d. **Model Q&A Pairs**

In the prompt section, you can also provide some model Q&A pairs. This lets the agent know what a good answer looks like. To add a pair, select the “Add Pair” button and insert your question and answer in the pop-out form.

![saved_suggested_questions_display.png](/docs/assets/agents/create-steps/agent_saved_suggested_questions.png)

Your Q&A pairs should reflect the form and depth of response you are looking for. For example, if your agent’s job is to review and summarize documents, your model Q&A should include a model example of a summary, showing the type of information that should be included.

### e. **Actions**

In this section, you can attach one or more **published actions** to the agent. Actions allow agents to dynamically connect to external systems or trigger workflows based on user input.

- Use the dropdown to search for and select an existing published action.  
- Choose **Create New Action** to define a new action and link it to this agent.  
- Existing actions in the list display their name, creator, and description (e.g., creating a Zendesk ticket, reading emails, posting in Slack channels, or creating Asana tasks).  

Attaching the right actions ensures that your agent can not only respond to questions but also execute real-world tasks across integrated systems.
![agent-existing-action-options.png](/docs/assets/agents/create-steps/agent-existing-action-options.png)


### f. **Data**

The data you provide will be the source of truth for your agent. Your agent will rely on this data (along with the prompt and Q&A pairs) to answer user queries.

   **Pinned Data** - By pinning data sources, you can instruct your agent to refer to certain sources when answering _every_ user query. You should use this for documents that will relate to most queries you expect your agent to address. If you have a document that you almost always want to agent to refer to, put it here. This could include answers to FAQs or a sales playbook. As pinned sources will be read in their entirety every time a user asks a question, they should only be used for a limited amount of high quality data to avoid overwhelming the AI with too much data on every question.
To use this feature, use the toggle to turn on pinned sources and search for sources to pin in the search bar below.

![Here, we pinned our infosec FAQs when setting up Credal’s Infosec agent. ](/docs/assets/copilots/pinned_infosec_FAQs_example.png)

Here, we pinned our infosec FAQs when setting up Credal’s Infosec agent.


1. **Searchable Sources**
   - You should also provide your agent with sufficient data relevant to its area of expertise. It will search these sources for information relevant to user queries. Use the toggle to enable searchable sources and use the search bar to add sources.

   ![We provided our infosec agent with all of Credal’s information security documentation.](/docs/assets/copilots/infosec_copilot_searchable_data_example.png)

   We provided our infosec agent with all of Credal’s information security documentation.

2. **Tailoring source retrieval**
   - When asked a question, your agent will search its sources for relevant pieces (or “chunks”) of information, which it will use to come up with a response. You can configure how the agent retrieves this information:

   ![tailoring_source_retrieval.gif](/docs/assets/copilots/tailoring_source_retrieval.gif)

   - **Number of chunks:** You can set the number of chunks the agent will draw on to answer questions. This number should be set the lowest possible value that generates accurate answers to avoid drawing too much data into every prompt (and overwhelming the AI). Generally, where agents will have to look at more than one document (or parts of a document) to answer a question, the number will be higher than if answers are located in a specified location (like a row of an FAQs document).
   - **Similarity threshold:** You can also set a similarity threshold, which mediates how similar a chunk must be to a prompt before it will be considered by the agent. For broader queries, a lower similarity threshold may be helpful to provide the agent with more context, while for more specific queries, a higher threshold will help the agent focus on only the correct response.

   When adjusting these settings, you may also want to consider spend—the more data you pull into each query, the more the cost will increase. Also, more data isn’t always more useful. Drawing too much data into each query can introduce noise and distract the agent from the relevant information. Optimizing these settings can help control spend and improve the focus and accuracy of responses.

<aside>
💡 Clearly naming your documents can help your agent distinguish and identify them. This can be helpful if you want to ask questions that refer to specific documents.

</aside>

iv. **User Inputs**

User Inputs are a way to provide your agent with additional context. This is particularly useful when you want to provide the agent with information that is not contained in the built in data sources, such as one off documents to analyze, or the input to your Agent's process.
Whether it’s an annual report, an incident Slack channel, or any other document, you can define what your Agent needs to search to address the prompt. User Inputs can be either specified as Pinned or Searchable Data, and these suggestions are then displayed below the Agent prompt.

![agent_user_inputs_section.png](/docs/assets/copilots/copilot_user_inputs_section.png)

### g. Tools

Agents have the ability to use predefined tools. Many of the tools are in Beta, so reach out to [support@credal.ai](mailto:support@credal.ai) if you have any questions or feedback.

![Agent Tools.png](/docs/assets/copilots/Copilot_Tools.png)

1. **Code Interpreter**
   1. Code Interpreter is primarily used to generate charts and graphs. Your agent will use the code interpreter tool to write a Python script, and will use that Python script to generate a chart or graph. The chart will be displayed visually in the message response.
   2. This feature is commonly used to plot data that’s extracted from a document or generated by the LLM.
   3. Only available when using OpenAI models.
   4. Streaming responses will be disabled when Code Interpreter is used.
2. **Smart Filtering**

   1. Your agent can use the Smart Filtering tool to automatically figure out exactly what data is relevant to the user’s question.
   2. The agent will generate filters based on the user’s question, then apply those filters to restrict what data it considers. This is what it looks like in action:

   ![Smart Filtering Example.png](/docs/assets/copilots/Smart_Filtering_Example.png)

   To use Smart Filtering, there are two prerequisites, a document collection with a meta schema and a agent searching the collection with Smart Filtering turned on. Collections can get metadata directly from source systems like Slack, or by using AI in the background to infer metadata values like account or project without structured data. Contact your Credal team for help with set up. For a self-serve option, follow the below steps:

   1. First, you must have a Document Collection attached in the Data section of the agent under “Search”.
      1. To create a document collection, navigate to [https://app.credal.ai/document-collections](https://app.credal.ai/document-collections) or click Document Collections in the left-hand menu.
   2. Second, the Document Collection must have a Schema configured:

      ![Add Schema.png](/docs/assets/copilots/Add_Schema.png)

   When configuring the Schema, there are a few things to keep in mind:

   - The Name must match the name of a metadata field you have on the documents in your collection. That metadata can be set when uploading the data via the [uploadDocumentContents API endpoint](https://docs.credal.ai/api-reference/document-catalog/metadata) or patched in after the fact using the [metadata endpoint](https://docs.credal.ai/api-reference/document-catalog/metadata).
   - The description is used by the LLM to decide when to filter on each field, so be as descriptive as possible.
   - Checking “Categorical” indicates that there are a small number of values this field might have (less than 50). When it is checked, Credal will detect all the possible values and provide those to the LLM so that it knows what values it can filter for.

![Schema Configuration.png](/docs/assets/copilots/Schema_Configuration.png)

The LLM may not always get the filters right on the first try. You can always edit the filters by clicking on them, and then regenerate the message.

**iii. Web Search**

1. Web Search lets your agent search the web for relevant sources, then use those sources to generate an answer.
2. Behind the scenes, the agent will use Bing to search the web based on the user’s question, then use up to five results.
3. Web Search can lead to higher latency due to the time it takes to search the web and crawl results.

**iv. Jira Ticket Creation**

1. Currently in private preview. Contact [support@credal.ai](mailto:support@credal.ai) for access.
